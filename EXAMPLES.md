

####################################################################################################
    CMD: [calc_date]
####################################################################################################

OUTPUT
================================

     
     USAGE: main [X days ago | X days]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [calc_date '20 days ago']
####################################################################################################

OUTPUT
================================

     2020.05.03
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [calc_date '20 days']
####################################################################################################

OUTPUT
================================

     2020.06.12
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [list_nodes]
####################################################################################################

OUTPUT
================================

     
     USAGE: list_nodes [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [list_nodes l]
####################################################################################################

OUTPUT
================================

     
     ip              heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name                  disk.total disk.used disk.avail disk.used_percent
     192.168.112.141           75          99   6    1.61    2.19     2.45 dl        -      lab-rdu-es-data-01a        5.8tb     4.3tb      1.4tb             74.67
     192.168.112.142           52          84   4    1.51    2.07     2.08 dl        -      lab-rdu-es-data-01b        5.8tb     4.1tb      1.6tb             71.54
     192.168.112.143           52         100   6    4.57    3.46     3.03 dl        -      lab-rdu-es-data-01c        5.8tb     4.2tb      1.5tb             73.24
     192.168.116.29            69          86   9    3.66    3.16     3.01 dl        -      lab-rdu-es-data-01d        6.9tb       4tb      2.9tb             58.13
     192.168.116.30            36         100  44   22.27   21.58    22.98 dl        -      lab-rdu-es-data-01e        6.9tb     2.5tb      4.4tb             36.20
     192.168.116.31            41          98  13    5.16    5.09     4.91 dl        -      lab-rdu-es-data-01f        6.9tb     4.2tb      2.7tb             60.79
     192.168.116.32            60         100   8    2.11    3.07     3.62 dl        -      lab-rdu-es-data-01g        6.9tb     4.2tb      2.7tb             61.02
     192.168.112.144           71          95   0    0.02    0.05     0.05 ilm       -      lab-rdu-es-master-01a     17.4gb       9gb      8.4gb             51.82
     192.168.112.145           25          95   3    0.06    0.08     0.06 ilm       -      lab-rdu-es-master-01b     17.4gb     9.4gb      7.9gb             54.38
     192.168.112.146            8          89  22    0.28    0.13     0.14 ilm       *      lab-rdu-es-master-01c     17.4gb     8.5gb      8.8gb             49.23
     192.168.116.120           11          62   0    0.08    0.04     0.05 l         -      lab-rdu-es-ml-01a         16.9gb     3.1gb     13.8gb             18.47
     192.168.116.121           12          61   1    0.00    0.01     0.05 l         -      lab-rdu-es-ml-01b         16.9gb       3gb     13.9gb             18.08
     
     valid data node suffixes: 1a,1b,1c,1d,1e,1f,1g
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [list_nodes_storage]
####################################################################################################

OUTPUT
================================

     
     USAGE: list_nodes_storage [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [list_nodes_storage l]
####################################################################################################

OUTPUT
================================

     
     ip              node.role master name                  disk.total disk.used disk.avail disk.used_percent
     192.168.112.141 dl        -      lab-rdu-es-data-01a        5.8tb     4.3tb      1.4tb             74.67
     192.168.112.143 dl        -      lab-rdu-es-data-01c        5.8tb     4.2tb      1.5tb             73.24
     192.168.112.142 dl        -      lab-rdu-es-data-01b        5.8tb     4.1tb      1.6tb             71.54
     192.168.116.32  dl        -      lab-rdu-es-data-01g        6.9tb     4.2tb      2.7tb             61.02
     192.168.116.31  dl        -      lab-rdu-es-data-01f        6.9tb     4.2tb      2.7tb             60.80
     192.168.116.29  dl        -      lab-rdu-es-data-01d        6.9tb       4tb      2.9tb             58.13
     192.168.112.145 ilm       -      lab-rdu-es-master-01b     17.4gb     9.4gb      7.9gb             54.38
     192.168.112.144 ilm       -      lab-rdu-es-master-01a     17.4gb       9gb      8.4gb             51.82
     192.168.112.146 ilm       *      lab-rdu-es-master-01c     17.4gb     8.5gb      8.8gb             49.23
     192.168.116.30  dl        -      lab-rdu-es-data-01e        6.9tb     2.5tb      4.4tb             36.20
     192.168.116.120 l         -      lab-rdu-es-ml-01a         16.9gb     3.1gb     13.8gb             18.47
     192.168.116.121 l         -      lab-rdu-es-ml-01b         16.9gb       3gb     13.9gb             18.08
     
     valid data node suffixes: 1a,1b,1c,1d,1e,1f,1g
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_nodes_fs_details]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_nodes_fs_details [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_nodes_fs_details l]
####################################################################################################

OUTPUT
================================

     {
       "_nodes": {
         "total": 12,
         "successful": 12,
         "failed": 0
       },
       "cluster_name": "lab-rdu-es-01",
       "nodes": {
         "0BzzZ7llQnenaeJWj7z-KQ": {
           "timestamp": 1590229034130,
           "name": "lab-rdu-es-ml-01b",
           "transport_address": "192.168.116.121:9300",
           "host": "192.168.116.121",
           "ip": "192.168.116.121:9300",
           "roles": [
             "ml"
           ],
           "attributes": {
             "ml.machine_memory": "16654659584",
             "ml.max_open_jobs": "20",
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_nodes_circuit-breaker_summary]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_nodes_circuit-breaker_summary [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_nodes_circuit-breaker_summary l]
####################################################################################################

OUTPUT
================================

     
     node circuit breakers tripped counts
     ---------------------------------------------------
     lab-rdu-es-data-01a:    request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-data-01b:    request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-data-01c:    request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-data-01d:    request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-data-01e:    request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-data-01f:    request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-data-01g:    request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-master-01a:  request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-master-01b:  request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-master-01c:  request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-ml-01a:      request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     lab-rdu-es-ml-01b:      request:  0  fielddata:  0  in_flight_requests:  0  accounting:  0  parent:  1
     
     --------- end of check ----------------------------
     
     
         Circuit Breakers
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_nodes_circuit-breaker_details]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_nodes_circuit-breaker_details [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_nodes_circuit-breaker_details l]
####################################################################################################

OUTPUT
================================

     {
       "_nodes": {
         "total": 12,
         "successful": 12,
         "failed": 0
       },
       "cluster_name": "lab-rdu-es-01",
       "nodes": {
         "0BzzZ7llQnenaeJWj7z-KQ": {
           "timestamp": 1590229035584,
           "name": "lab-rdu-es-ml-01b",
           "transport_address": "192.168.116.121:9300",
           "host": "192.168.116.121",
           "ip": "192.168.116.121:9300",
           "roles": [
             "ml"
           ],
           "attributes": {
             "ml.machine_memory": "16654659584",
             "ml.max_open_jobs": "20",
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_shards]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_shards [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_shards l]
####################################################################################################

OUTPUT
================================

     index                                   shard prirep state          docs   store ip              node
     filebeat-6.5.1-2020.05.13               0     p      STARTED    54019187  33.9gb 192.168.112.143 lab-rdu-es-data-01c
     filebeat-6.5.1-2020.05.13               0     r      STARTED    54019187  33.9gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.13               4     p      STARTED    54020326  33.9gb 192.168.116.29  lab-rdu-es-data-01d
     filebeat-6.5.1-2020.05.13               5     p      STARTED    54022266  33.9gb 192.168.116.32  lab-rdu-es-data-01g
     filebeat-6.5.1-2020.05.13               5     r      STARTED    54022266  33.9gb 192.168.116.31  lab-rdu-es-data-01f
     filebeat-6.5.1-2020.05.13               9     r      STARTED    54016528  33.9gb 192.168.112.143 lab-rdu-es-data-01c
     filebeat-6.5.1-2020.05.13               9     p      STARTED    54016528  33.9gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.13               7     r      STARTED    54024270  33.9gb 192.168.116.31  lab-rdu-es-data-01f
     filebeat-6.5.1-2020.05.13               7     p      STARTED    54024270  33.9gb 192.168.116.32  lab-rdu-es-data-01g
     filebeat-6.5.1-2020.05.13               3     p      STARTED    54025261  33.9gb 192.168.116.32  lab-rdu-es-data-01g
     filebeat-6.5.1-2020.05.13               3     r      STARTED    54025261  33.9gb 192.168.116.31  lab-rdu-es-data-01f
     filebeat-6.5.1-2020.05.13               8     p      STARTED    54003201  33.9gb 192.168.116.29  lab-rdu-es-data-01d
     filebeat-6.5.1-2020.05.13               1     r      STARTED    54011737  33.9gb 192.168.112.143 lab-rdu-es-data-01c
     filebeat-6.5.1-2020.05.13               1     p      STARTED    54011737  33.9gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.13               2     r      STARTED    54008159  33.6gb 192.168.116.30  lab-rdu-es-data-01e
     filebeat-6.5.1-2020.05.13               2     p      STARTED    54008159  33.6gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.08               4     r      STARTED    59261488  33.6gb 192.168.116.31  lab-rdu-es-data-01f
     filebeat-6.5.1-2020.05.13               4     r      STARTED    54020326  33.6gb 192.168.112.142 lab-rdu-es-data-01b
     filebeat-6.5.1-2020.05.08               1     r      STARTED    59250273  33.6gb 192.168.112.142 lab-rdu-es-data-01b
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_big_shards]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_big_shards [l|p|c] <node suffix--[1a|1b|1c|1d...]>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_big_shards l 1a]
####################################################################################################

OUTPUT
================================

     index                                   shard prirep state          docs    store ip              node
     filebeat-6.5.1-2020.05.13               0     r      STARTED    54019187   33.9gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.13               9     p      STARTED    54016528   33.9gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.13               1     p      STARTED    54011737   33.9gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.13               2     p      STARTED    54008159   33.6gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.08               2     r      STARTED    59254605   33.3gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.08               4     p      STARTED    59261488   33.2gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.08               3     p      STARTED    59244286   33.2gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.05               6     p      STARTED    53887280   30.9gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.05               8     r      STARTED    53879844   30.8gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.05               9     r      STARTED    53871890   30.8gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.04.10               5     p      STARTED    55091563   30.7gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.04.10               9     r      STARTED    55112824   30.7gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.04.10               6     r      STARTED    55102039   30.7gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.06               6     r      STARTED    53747279   30.1gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.06               4     p      STARTED    53737375   30.1gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.06               2     r      STARTED    53736498   30.1gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.06               8     p      STARTED    53745094   30.1gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.15               1     p      STARTED    52695964     30gb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.05.15               5     r      STARTED    52657395     30gb 192.168.112.141 lab-rdu-es-data-01a
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_small_shards]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_small_shards [l|p|c] <node suffix--[1a|1b|1c|1d...]>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_small_shards l 1a]
####################################################################################################

OUTPUT
================================

     filebeat-6.5.1-2020.12.29               7     p      STARTED           3   28.3kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.04.04               4     r      STARTED           4   27.2kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.12.27               0     r      STARTED           7   25.1kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.12.31               14    r      STARTED           7   24.1kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.03.28               3     p      STARTED          30   23.9kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.12.31               8     r      STARTED           8     23kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.12.31               2     r      STARTED           8     23kb 192.168.112.141 lab-rdu-es-data-01a
     watcher                                 0     p      STARTED           1   21.6kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.04.04               10    r      STARTED          10   19.8kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.12.29               12    p      STARTED           2   19.3kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.03.27               2     p      STARTED           4   18.5kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.03.27               8     r      STARTED           4   18.4kb 192.168.112.141 lab-rdu-es-data-01a
     .management-beats                       0     r      STARTED           3   18.4kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.03.15               4     r      STARTED           3   18.2kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.03.05               3     r      STARTED           5   16.3kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.03.05               9     r      STARTED           5   15.9kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.12.29               6     r      STARTED           6   15.4kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.12.29               1     r      STARTED           5   15.2kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.03.10               5     r      STARTED           4   13.3kb 192.168.112.141 lab-rdu-es-data-01a
     filebeat-6.5.1-2020.12.28               7     r      STARTED           2   12.5kb 192.168.112.141 lab-rdu-es-data-01a
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_shard_usage_by_node]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_shard_usage_by_node [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_shard_usage_by_node l]
####################################################################################################

OUTPUT
================================

     
     
     A good rule-of-thumb is to ensure you keep the number of shards per node below 20 per GB heap it 
     has configured. A node with a 30GB heap should therefore have a maximum of 600 shards, but the 
     further below this limit you can keep it the better. This will generally help the cluster 
     stay in good health.
     
     Source: https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster
     
     
     node                 #shards
     ----                 -------
     lab-rdu-es-data-01a  412
     lab-rdu-es-data-01b  414
     lab-rdu-es-data-01c  413
     lab-rdu-es-data-01d  413
     lab-rdu-es-data-01e  404
     lab-rdu-es-data-01f  412
     lab-rdu-es-data-01g  413
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [relo_shard]
####################################################################################################

OUTPUT
================================

     
     USAGE: relo_shard [l|p|c] <shard name> <shard num> <from node> <to node>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [cancel_relo_shard]
####################################################################################################

OUTPUT
================================

     
     USAGE: cancel_relo_shard [l|p|c] <shard name> <shard num> <from/to node>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [cancel_relo_shards_all]
####################################################################################################

OUTPUT
================================

     
     USAGE: cancel_relo_shards_all [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [retry_unassigned_shards]
####################################################################################################

OUTPUT
================================

     
     USAGE: retry_unassigned_shards [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_balance_throttle l]
####################################################################################################

OUTPUT
================================

         "ccr.indices.recovery.max_bytes_per_sec": "40mb",
         "cluster.routing.allocation.cluster_concurrent_rebalance": "2",
         "cluster.routing.allocation.node_concurrent_incoming_recoveries": "2",
         "cluster.routing.allocation.node_concurrent_outgoing_recoveries": "2",
         "cluster.routing.allocation.node_concurrent_recoveries": "2",
         "cluster.routing.allocation.node_initial_primaries_recoveries": "4",
         "cluster.routing.allocation.type": "balanced",
         "indices.recovery.max_bytes_per_sec": "40mb",
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [increase_balance_throttle]
####################################################################################################

OUTPUT
================================

     
     USAGE: increase_balance_throttle [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [increase_balance_throttle_XXXmb]
####################################################################################################

OUTPUT
================================

     
     USAGE: increase_balance_throttle_XXXmb [l|p|c] <size in megabytes>
     
       * size in megabytes: [40|100|250|500|2000|etc.]
     
       NOTE: ...minimum is 40, the max. 2000!...
     
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [reset_balance_throttle]
####################################################################################################

OUTPUT
================================

     
     USAGE: reset_balance_throttle [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [change_allocation_threshold]
####################################################################################################

OUTPUT
================================

     
     USAGE: change_allocation_threshold [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_recovery]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_recovery [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_recovery l]
####################################################################################################

OUTPUT
================================

     index                      shard  time   type  stage  source_node  target_node  files  files_recovered  files_percent  bytes_total  bytes_percent  translog_ops_recovered  translog_ops  translog_ops_percent
     filebeat-6.5.1-2020.05.12  1      24.9m  peer  index  01g          01e          163    162              99.4%          30405136392  94.5%          0                       0             100.0%
     filebeat-6.5.1-2020.04.25  1      22.9m  peer  index  01g          01e          168    166              98.8%          30222426996  86.9%          0                       0             100.0%
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_recovery_full]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_recovery_full [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_recovery_full l]
####################################################################################################

OUTPUT
================================

     index                                   shard time  type           stage source_host     source_node         target_host     target_node         repository snapshot files files_recovered files_percent files_total bytes       bytes_recovered bytes_percent bytes_total translog_ops translog_ops_recovered translog_ops_percent
     filebeat-6.5.1-2020.05.12               1     24.9m peer           index 192.168.116.32  lab-rdu-es-data-01g 192.168.116.30  lab-rdu-es-data-01e n/a        n/a      163   162             99.4%         163         30405136392 28745976440     94.5%         30405136392 0            0                      100.0%
     filebeat-6.5.1-2020.04.25               1     22.9m peer           index 192.168.116.32  lab-rdu-es-data-01g 192.168.116.30  lab-rdu-es-data-01e n/a        n/a      168   166             98.8%         168         30222426996 26302729370     87.0%         30222426996 0            0                      100.0%
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [enable_readonly_idx_pattern]
####################################################################################################

OUTPUT
================================

     
     USAGE: enable_readonly_idx_pattern [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [disable_readonly_idx_pattern]
####################################################################################################

OUTPUT
================================

     
     USAGE: disable_readonly_idx_pattern [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [enable_readonly_idxs]
####################################################################################################

OUTPUT
================================

     
     USAGE: enable_readonly_idxs [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [disable_readonly_idxs]
####################################################################################################

OUTPUT
================================

     
     USAGE: disable_readonly_idxs [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_readonly_idxs]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_readonly_idxs [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_readonly_idxs l]
####################################################################################################

OUTPUT
================================

     
     indices with read_only flag set (true)
     ---------------------------------------------------
     
     --------- end of check ----------------------------
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_readonly_idxs_full]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_readonly_idxs_full [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_readonly_idxs_full l]
####################################################################################################

OUTPUT
================================

     ".apm-agent-configuration"                 :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".kibana_10"                               :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".kibana_11"                               :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".kibana_7"                                :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".kibana_8"                                :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".kibana_9"                                :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".kibana_task_manager_1"                   :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".management-beats"                        :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".ml-annotations-6"                        :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".ml-anomalies-custom-k8s-ml-fb-test-100"  :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".ml-anomalies-shared"                     :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".ml-config"                               :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".ml-notifications-000001"                 :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".ml-state"                                :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".monitoring-alerts-7"                     :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".monitoring-es-7-2020.05.17"              :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".monitoring-es-7-2020.05.18"              :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".monitoring-es-7-2020.05.19"              :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".monitoring-es-7-2020.05.20"              :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
     ".monitoring-es-7-2020.05.21"              :{  "defaults"  :{  "index"  :{  "blocks"  :{  "read_only"  :  "false"  }  }  }  },
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [clear_readonlyallowdel_idxs]
####################################################################################################

OUTPUT
================================

     
     USAGE: clear_readonlyallowdel_idxs [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [set_idx_default_field]
####################################################################################################

OUTPUT
================================

     
     USAGE: set_idx_default_field [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [set_tmplate_default_field]
####################################################################################################

OUTPUT
================================

     
     USAGE: set_tmplate_default_field [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [set_idx_num_replicas_to_X]
####################################################################################################

OUTPUT
================================

     
     USAGE: set_idx_num_replicas_to_X [l|p|c] <idx pattern> <shard replica count>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_health]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_health [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_health l]
####################################################################################################

OUTPUT
================================

     {
       "cluster_name" : "lab-rdu-es-01",
       "status" : "green",
       "timed_out" : false,
       "number_of_nodes" : 12,
       "number_of_data_nodes" : 7,
       "active_primary_shards" : 1438,
       "active_shards" : 2881,
       "relocating_shards" : 2,
       "initializing_shards" : 0,
       "unassigned_shards" : 0,
       "delayed_unassigned_shards" : 0,
       "number_of_pending_tasks" : 0,
       "number_of_in_flight_fetch" : 0,
       "task_max_waiting_in_queue_millis" : 0,
       "active_shards_percent_as_number" : 100.0
     }
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_watermarks]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_watermarks [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_watermarks l]
####################################################################################################

OUTPUT
================================

         "cluster.routing.allocation.disk.watermark.flood_stage" : "50gb",
         "cluster.routing.allocation.disk.watermark.high" : "100gb",
         "cluster.routing.allocation.disk.watermark.low" : "150gb",
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_state]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_state [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_state l]
####################################################################################################

OUTPUT
================================

     index                                   shard prirep state          docs store ip              node
     filebeat-6.5.1-2020.04.25               1     r      RELOCATING 72828968    28 192.168.112.141 lab-rdu-es-data-01a -> 192.168.116.30 _N1uuYoxTgOrgbB2l-vg2w lab-rdu-es-data-01e
     filebeat-6.5.1-2020.05.12               1     r      RELOCATING 47009752    28 192.168.112.142 lab-rdu-es-data-01b -> 192.168.116.30 _N1uuYoxTgOrgbB2l-vg2w lab-rdu-es-data-01e
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_cluster]
####################################################################################################

OUTPUT
================================

     
     USAGE: showcfg_cluster [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_cluster l]
####################################################################################################

OUTPUT
================================

     {
       "persistent" : {
         "cluster.routing.allocation.balance.threshold" : "3.0",
         "xpack.monitoring.collection.enabled" : "true"
       },
       "transient" : {
         "cluster.routing.allocation.enable" : "all"
       },
       "defaults" : {
         "action.auto_create_index" : "true",
         "action.destructive_requires_name" : "false",
         "action.search.shard_count.limit" : "9223372036854775807",
         "bootstrap.ctrlhandler" : "true",
         "bootstrap.memory_lock" : "false",
         "bootstrap.system_call_filter" : "true",
         "cache.recycler.page.limit.heap" : "10%",
         "cache.recycler.page.type" : "CONCURRENT",
         "cache.recycler.page.weight.bytes" : "1.0",
         "cache.recycler.page.weight.ints" : "1.0",
         "cache.recycler.page.weight.longs" : "1.0",
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showrecov_stats]
####################################################################################################

OUTPUT
================================

     
     USAGE: showrecov_stats [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showrecov_stats l]
####################################################################################################

OUTPUT
================================

     {
       ".reporting-2020.02.02": {
         "shards": [
           {
             "id": 0,
             "type": "PEER",
             "stage": "DONE",
             "primary": false,
             "start_time_in_millis": 1589557023358,
             "stop_time_in_millis": 1589557023889,
             "total_time_in_millis": 530,
             "source": {
               "id": "N3zJNxghRvuwRp6SBnRW7Q",
               "host": "192.168.116.30",
               "transport_address": "192.168.116.30:9300",
               "ip": "192.168.116.30",
               "name": "lab-rdu-es-data-01e"
             },
             "target": {
               "id": "P4uG_g_JTiC2xk14UpZdIA",
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [shorecov_hot_threads]
####################################################################################################

OUTPUT
================================

     
     USAGE: shorecov_hot_threads [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [shorecov_hot_threads l]
####################################################################################################

OUTPUT
================================

     ::: {lab-rdu-es-data-01a}{vudQxvnfSQuxMtdkq8ZTUQ}{nK86NcYDRluGGXlLMY4VHA}{192.168.112.141}{192.168.112.141:9300}{dl}{ml.machine_memory=134924824576, xpack.installed=true, ml.max_open_jobs=20}
        Hot threads at 2020-05-23T10:17:40.184Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:
        
        49.1% (245.4ms out of 500ms) cpu usage by thread 'elasticsearch[lab-rdu-es-data-01a][[filebeat-6.5.1-2020.05.23][10]: Lucene Merge Thread #3147]'
          2/10 snapshots sharing following 15 elements
            app//org.apache.lucene.index.MappingMultiPostingsEnum$MappingPostingsSub.nextDoc(MappingMultiPostingsEnum.java:51)
            app//org.apache.lucene.index.DocIDMerger$SequentialDocIDMerger.next(DocIDMerger.java:99)
            app//org.apache.lucene.index.MappingMultiPostingsEnum.nextDoc(MappingMultiPostingsEnum.java:103)
            app//org.apache.lucene.codecs.PushPostingsWriterBase.writeTerm(PushPostingsWriterBase.java:135)
            app//org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.write(BlockTreeTermsWriter.java:865)
            app//org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.write(BlockTreeTermsWriter.java:344)
            app//org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:105)
            app//org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsWriter.merge(PerFieldPostingsFormat.java:197)
            app//org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:245)
            app//org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:140)
            app//org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4463)
            app//org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:4057)
            app//org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:625)
            app//org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:101)
            app//org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:662)
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [shorecov_idx_shard_stats]
####################################################################################################

OUTPUT
================================

     
     USAGE: shorecov_idx_shard_stats [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [shorecov_idx_shard_stats l filebeat*2020.05.22]
####################################################################################################

OUTPUT
================================

     {
       "_shards": {
         "total": 36,
         "successful": 36,
         "failed": 0
       },
       "_all": {
         "primaries": {
           "docs": {
             "count": 470363689,
             "deleted": 0
           },
           "store": {
             "size_in_bytes": 360335873840
           },
           "indexing": {
             "index_total": 404499772,
             "index_time_in_millis": 203101930,
             "index_current": 0,
             "index_failed": 0,
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_stats_cluster]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_stats_cluster [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_stats_cluster l]
####################################################################################################

OUTPUT
================================

     {
       "_shards": {
         "total": 2881,
         "successful": 2881,
         "failed": 0
       },
       "_all": {
         "primaries": {
           "docs": {
             "count": 28073915047,
             "deleted": 10787760
           },
           "store": {
             "size": "13.8tb",
             "size_in_bytes": 15268994857767
           },
           "indexing": {
             "index_total": 8329048466,
             "index_time": "32d",
             "index_time_in_millis": 2771071091,
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_tasks_stats]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_tasks_stats [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_tasks_stats l]
####################################################################################################

OUTPUT
================================

     action                                       task_id                           parent_task_id                    type       start_time    timestamp running_time ip              node                  description
     xpack/ml/job[c]                              78XQr5xST0KCwCsBy6KwlA:5057769430 cluster:54                        persistent 1590004175710 19:49:35  2.6d         192.168.112.143 lab-rdu-es-data-01c   job-filebeat-k8s-ns-all
     xpack/rollup/job[c]                          78XQr5xST0KCwCsBy6KwlA:5345824570 cluster:57                        persistent 1590096694435 21:31:34  1.5d         192.168.112.143 lab-rdu-es-data-01c   rollup_akrzos-k8scapcity-test01
     xpack/ml/job[c]                              vudQxvnfSQuxMtdkq8ZTUQ:5464134186 cluster:58                        persistent 1590160885159 15:21:25  18.9h        192.168.112.141 lab-rdu-es-data-01a   job-k8s-ml-fb-test-100
     xpack/ml/datafeed[c]                         vudQxvnfSQuxMtdkq8ZTUQ:5464136691 cluster:59                        persistent 1590160886741 15:21:26  18.9h        192.168.112.141 lab-rdu-es-data-01a   datafeed-datafeed-k8s-ml-fb-test-100
     internal:index/shard/recovery/start_recovery WuOMAIxrRcKG8TqPy8Zleg:1161454549 -                                 transport  1590227553540 09:52:33  25.2m        192.168.116.32  lab-rdu-es-data-01g   
     internal:index/shard/recovery/start_recovery WuOMAIxrRcKG8TqPy8Zleg:1161517630 -                                 transport  1590227671819 09:54:31  23.2m        192.168.116.32  lab-rdu-es-data-01g   
     indices:data/write/bulk                      P4uG_g_JTiC2xk14UpZdIA:4713198167 -                                 transport  1590229067147 10:17:47  101.8ms      192.168.116.29  lab-rdu-es-data-01d   requests[125], indices[filebeat-flow-2020.05.23-10]
     indices:data/write/bulk[s]                   P4uG_g_JTiC2xk14UpZdIA:4713198168 P4uG_g_JTiC2xk14UpZdIA:4713198167 transport  1590229067148 10:17:47  101.4ms      192.168.116.29  lab-rdu-es-data-01d   requests[125], index[filebeat-flow-2020.05.23-10][0]
     indices:data/write/bulk[s]                   _N1uuYoxTgOrgbB2l-vg2w:153565561  P4uG_g_JTiC2xk14UpZdIA:4713198168 transport  1590229067183 10:17:47  65.3ms       192.168.116.30  lab-rdu-es-data-01e   requests[125], index[filebeat-flow-2020.05.23-10][0]
     indices:data/write/bulk[s][p]                _N1uuYoxTgOrgbB2l-vg2w:153565570  _N1uuYoxTgOrgbB2l-vg2w:153565561  direct     1590229067184 10:17:47  64.3ms       192.168.116.30  lab-rdu-es-data-01e   requests[125], index[filebeat-flow-2020.05.23-10][0]
     indices:data/write/bulk[s][r]                3is48GZERPOBPNbNpPXs3Q:111983614  _N1uuYoxTgOrgbB2l-vg2w:153565561  transport  1590229067234 10:17:47  15.4ms       192.168.116.31  lab-rdu-es-data-01f   requests[125], index[filebeat-flow-2020.05.23-10][0]
     indices:data/write/bulk                      WuOMAIxrRcKG8TqPy8Zleg:1162244090 -                                 transport  1590229067147 10:17:47  102.5ms      192.168.116.32  lab-rdu-es-data-01g   requests[125], indices[filebeat-flow-2020.05.23-10]
     indices:data/write/bulk[s]                   WuOMAIxrRcKG8TqPy8Zleg:1162244091 WuOMAIxrRcKG8TqPy8Zleg:1162244090 transport  1590229067147 10:17:47  102.3ms      192.168.116.32  lab-rdu-es-data-01g   requests[125], index[filebeat-flow-2020.05.23-10][0]
     indices:data/write/bulk[s]                   _N1uuYoxTgOrgbB2l-vg2w:153565575  WuOMAIxrRcKG8TqPy8Zleg:1162244091 transport  1590229067186 10:17:47  63.1ms       192.168.116.30  lab-rdu-es-data-01e   requests[125], index[filebeat-flow-2020.05.23-10][0]
     indices:data/write/bulk[s][p]                _N1uuYoxTgOrgbB2l-vg2w:153565578  _N1uuYoxTgOrgbB2l-vg2w:153565575  direct     1590229067186 10:17:47  62.3ms       192.168.116.30  lab-rdu-es-data-01e   requests[125], index[filebeat-flow-2020.05.23-10][0]
     indices:data/write/bulk[s][r]                3is48GZERPOBPNbNpPXs3Q:111983612  _N1uuYoxTgOrgbB2l-vg2w:153565575  transport  1590229067229 10:17:47  20.1ms       192.168.116.31  lab-rdu-es-data-01f   requests[125], index[filebeat-flow-2020.05.23-10][0]
     indices:data/write/bulk                      WuOMAIxrRcKG8TqPy8Zleg:1162244121 -                                 transport  1590229067192 10:17:47  57.7ms       192.168.116.32  lab-rdu-es-data-01g   requests[125], indices[filebeat-flow-2020.05.23-10]
     indices:data/write/bulk[s]                   WuOMAIxrRcKG8TqPy8Zleg:1162244122 WuOMAIxrRcKG8TqPy8Zleg:1162244121 transport  1590229067192 10:17:47  57.4ms       192.168.116.32  lab-rdu-es-data-01g   requests[125], index[filebeat-flow-2020.05.23-10][0]
     indices:data/write/bulk[s]                   _N1uuYoxTgOrgbB2l-vg2w:153565646  WuOMAIxrRcKG8TqPy8Zleg:1162244122 transport  1590229067196 10:17:47  53ms         192.168.116.30  lab-rdu-es-data-01e   requests[125], index[filebeat-flow-2020.05.23-10][0]
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [verify_idx_retentions]
####################################################################################################

OUTPUT
================================

     
     USAGE: verify_idx_retentions [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [verify_idx_retentions l]
####################################################################################################

OUTPUT
================================

     
     NOTE: Shows how many days worth of logs per index. Some indices have multiple versions per index type.
     
     filebeat
     ==========
        4 6.2.3
       70 6.5.1
       44 7.6.2
       44 default
       90 flow
     
     Indexes dated in future: 6
     
     
     packetbeat
     ==========
       14 default
     
     
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_retention_violations]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_idx_retention_violations [l|p|c] <idx base type> <days to retain>
     
       * idx base type:  [filebeat|metricbeat|packetbeat|etc.]
       * days to retain: [30|60|90|etc.]
     
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_retention_violations l filebeat 30]
####################################################################################################

OUTPUT
================================

     
     
     Indices outside 30 day(s) retention window
     ==========================================
     Index Sub-Type: [6.2.3]
     ==========================================
     
     
     
     Indices outside 30 day(s) retention window
     ==========================================
     Index Sub-Type: [6.5.1]
     ==========================================
     
     filebeat-6.5.1-2020.03.05
     filebeat-6.5.1-2020.03.10
     filebeat-6.5.1-2020.03.11
     filebeat-6.5.1-2020.03.14
     filebeat-6.5.1-2020.03.15
     filebeat-6.5.1-2020.03.19
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_doc_sources_1st_10k]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_idx_doc_sources_1st_10k [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_doc_sources_1st_10k l filebeat*2020.05.22]
####################################################################################################

OUTPUT
================================

     
     
     Document sources (1st 10)
     =========================
     Total Docs: [470363689]
     =========================
     
     [  "filebeat-6.2.3-2020.05.22",  "hv-14.lab1.bandwidthclec.local",  "2020-05-22T00:02:24.000Z"  ]
     [  "filebeat-6.2.3-2020.05.22",  "hv-14.lab1.bandwidthclec.local",  "2020-05-22T00:02:24.000Z"  ]
     [  "filebeat-6.2.3-2020.05.22",  "hv-14.lab1.bandwidthclec.local",  "2020-05-22T00:02:24.000Z"  ]
     [  "filebeat-6.2.3-2020.05.22",  "hv-14.lab1.bandwidthclec.local",  "2020-05-22T00:02:24.000Z"  ]
     [  "filebeat-6.2.3-2020.05.22",  "hv-14.lab1.bandwidthclec.local",  "2020-05-22T00:02:24.000Z"  ]
     [  "filebeat-6.2.3-2020.05.22",  "hv-14.lab1.bandwidthclec.local",  "2020-05-22T00:02:24.000Z"  ]
     [  "filebeat-6.2.3-2020.05.22",  "hv-14.lab1.bandwidthclec.local",  "2020-05-22T00:02:24.000Z"  ]
     [  "filebeat-6.2.3-2020.05.22",  "hv-14.lab1.bandwidthclec.local",  "2020-05-22T00:02:24.000Z"  ]
     [  "filebeat-6.2.3-2020.05.22",  "hv-14.lab1.bandwidthclec.local",  "2020-05-22T00:02:24.000Z"  ]
     [  "filebeat-6.2.3-2020.05.22",  "hv-14.lab1.bandwidthclec.local",  "2020-05-22T00:02:24.000Z"  ]
     
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_doc_sources_all_cnts]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_idx_doc_sources_all_cnts [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_doc_sources_all_cnts l filebeat*2020.05.22]
####################################################################################################

OUTPUT
================================

     
     
     Document sources (counts)
     =========================
     
     {  "key":  "ocp-app-01i.lab1.bandwidthclec.local",                  "doc_count":  68227870  }
     {  "key":  "ocp-app-01h.lab1.bandwidthclec.local",                  "doc_count":  33603454  }
     {  "key":  "ocp-app-01j.lab1.bandwidthclec.local",                  "doc_count":  30737544  }
     {  "key":  "ocp-app-01c.lab1.bandwidthclec.local",                  "doc_count":  22959855  }
     {  "key":  "ocp-app-01k.lab1.bandwidthclec.local",                  "doc_count":  21726876  }
     {  "key":  "ocp-app-01l.lab1.bandwidthclec.local",                  "doc_count":  19200386  }
     {  "key":  "ip-10-23-17-93",                                        "doc_count":  18452802  }
     {  "key":  "ocp-app-01g.lab1.bandwidthclec.local",                  "doc_count":  15787257  }
     {  "key":  "ocp-app-01o.lab1.bwnet.us",                             "doc_count":  15452162  }
     {  "key":  "ocp-app-01f.lab1.bandwidthclec.local",                  "doc_count":  15063941  }
     {  "key":  "ocp-app-01n.lab1.bwnet.us",                             "doc_count":  14902454  }
     {  "key":  "ocp-infra-01a.lab1.bandwidthclec.local",                "doc_count":  13703548  }
     {  "key":  "ocp-app-01d.lab1.bandwidthclec.local",                  "doc_count":  12961315  }
     {  "key":  "ocp-app-01m.lab1.bandwidthclec.local",                  "doc_count":  11858822  }
     {  "key":  "ocp-app-01p.lab1.bwnet.us",                             "doc_count":  11795173  }
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_doc_sources_all_k8sns_cnts]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_idx_doc_sources_all_k8sns_cnts [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_doc_sources_all_k8sns_cnts l filebeat*2020.05.22]
####################################################################################################

OUTPUT
================================

     
     
     k8s document sources (counts)
     =============================
     
     "ksql-server"                         "2020-05-22T00:00:00.000Z"  33307692
     "kafka-connect"                       "2020-05-22T00:00:00.000Z"  30150896
     "argo-ci"                             "2020-05-22T00:00:00.000Z"  26402891
     "one-id"                              "2020-05-22T00:00:00.000Z"  23023623
     "correlator"                          "2020-05-22T00:00:00.000Z"  22211501
     "ls-indexer"                          "2020-05-22T00:00:00.000Z"  21950883
     "correlator-staging"                  "2020-05-22T00:00:00.000Z"  21461437
     "openshift-metrics-server"            "2020-05-22T00:00:00.000Z"  15415922
     "big-dipper-rbenson"                  "2020-05-22T00:00:00.000Z"  12733913
     "os-jenkins-cgaertner"                "2020-05-22T00:00:00.000Z"  7895584
     "http-voice-v2"                       "2020-05-22T00:00:00.000Z"  6099378
     "one-id-hfuss"                        "2020-05-22T00:00:00.000Z"  4909557
     "datadog"                             "2020-05-22T00:00:00.000Z"  4494301
     "datadog-jkost"                       "2020-05-22T00:00:00.000Z"  3113771
     "one-id-bkimbrough"                   "2020-05-22T00:00:00.000Z"  3098193
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_num_shards_per_idx]
####################################################################################################

OUTPUT
================================

     
     USAGE: showcfg_num_shards_per_idx [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_num_shards_per_idx l]
####################################################################################################

OUTPUT
================================

     {   ".monitoring-alerts"                            :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".data-frame-internal-1"                        :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".data-frame-internal-2"                        :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".data-frame-notifications-1"                   :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".kibana_task_manager"                          :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".logstash-management"                          :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".management-beats"                             :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".ml-config"                                    :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".ml-inference-000001"                          :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".ml-meta"                                      :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".ml-notifications"                             :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".ml-notifications-000001"                      :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".monitoring-alerts-7"                          :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".monitoring-beats"                             :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".monitoring-es"                                :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".monitoring-kibana"                            :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".monitoring-logstash"                          :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".slm-history"                                  :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".transform-internal-003"                       :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
     },  ".transform-internal-004"                       :  {  "settings"  :  {  "index"  :  {  "number_of_shards"  :  "1"   }  }
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_shard_allocations]
####################################################################################################

OUTPUT
================================

     
     USAGE: showcfg_shard_allocations [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_shard_allocations l]
####################################################################################################

OUTPUT
================================

     
     REFS
     ----
      - https://www.elastic.co/guide/en/elasticsearch/reference/current/shards-allocation.html#_shard_allocation_settings
      - https://www.elastic.co/guide/en/elasticsearch/reference/current/disk-allocator.html
     
     Shard Allocation Settings
     -------------------------
         "cluster.routing.allocation.enable" : "all"
         "ccr.indices.recovery.max_bytes_per_sec" : "40mb",
         "cluster.routing.allocation.node_concurrent_incoming_recoveries" : "2",
         "cluster.routing.allocation.node_concurrent_outgoing_recoveries" : "2",
         "cluster.routing.allocation.node_concurrent_recoveries" : "2",
         "cluster.routing.allocation.node_initial_primaries_recoveries" : "4",
         "cluster.routing.allocation.same_shard.host" : "false",
         "indices.recovery.max_bytes_per_sec" : "40mb",
     
     Shard Rebalancing Settings
     --------------------------
         "cluster.routing.allocation.allow_rebalance" : "indices_all_active",
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [explain_allocations]
####################################################################################################

OUTPUT
================================

     
     USAGE: explain_allocations [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [explain_allocations l]
####################################################################################################

OUTPUT
================================

     {
       "error": {
         "root_cause": [
           {
             "type": "illegal_argument_exception",
             "reason": "unable to find any unassigned shards to explain [ClusterAllocationExplainRequest[useAnyUnassignedShard=true,includeYesDecisions?=false]"
           }
         ],
         "type": "illegal_argument_exception",
         "reason": "unable to find any unassigned shards to explain [ClusterAllocationExplainRequest[useAnyUnassignedShard=true,includeYesDecisions?=false]"
       },
       "status": 400
     }
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [explain_allocations_hddinfo]
####################################################################################################

OUTPUT
================================

     
     USAGE: explain_allocations_hddinfo [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [explain_allocations_hddinfo l]
####################################################################################################

OUTPUT
================================

     
     USAGE: explain_allocations_hddinfo [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_shard_routing_allocation]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_shard_routing_allocation [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_shard_routing_allocation l]
####################################################################################################

OUTPUT
================================

         "cluster.routing.allocation.enable" : "all"
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [enable_shard_allocations]
####################################################################################################

OUTPUT
================================

     
     USAGE: enable_shard_allocations [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [enable_shard_allocations l]
####################################################################################################

OUTPUT
================================

     {"acknowledged":true,"persistent":{},"transient":{"cluster":{"routing":{"allocation":{"enable":"all"}}}}}
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [disable_shard_allocations]
####################################################################################################

OUTPUT
================================

     
     USAGE: disable_shard_allocations [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [clear_shard_allocations]
####################################################################################################

OUTPUT
================================

     
     USAGE: clear_shard_allocations [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_sizes]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_idx_sizes [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_sizes l]
####################################################################################################

OUTPUT
================================

     index                                   pri rep docs.count pri.store.size
     filebeat-6.5.1-2020.05.18                15   1  695777586            396
     filebeat-6.5.1-2020.05.19                15   1  627296284            345
     filebeat-6.5.1-2020.05.17                15   1  651301843            344
     filebeat-6.5.1-2020.05.13                10   1  540150677            338
     filebeat-6.5.1-2020.05.08                10   1  592501109            334
     filebeat-6.5.1-2020.05.20                15   1  589987848            332
     filebeat-6.5.1-2020.05.22                15   1  446271913            331
     filebeat-6.5.1-2020.05.21                15   1  523564915            316
     filebeat-6.5.1-2020.05.05                10   1  538873124            309
     filebeat-6.5.1-2020.04.10                10   1  551015493            309
     filebeat-6.5.1-2020.05.06                10   1  537454462            302
     filebeat-6.5.1-2020.05.15                10   1  526737791            300
     filebeat-6.5.1-2020.05.14                10   1  496991794            300
     filebeat-6.5.1-2020.05.16                15   1  584272729            293
     filebeat-6.5.1-2020.05.12                10   1  470190548            283
     filebeat-6.5.1-2020.04.25                10   1  728213394            281
     filebeat-6.5.1-2020.04.26                10   1  663323401            280
     filebeat-6.5.1-2020.04.16                10   1  490380679            279
     filebeat-6.5.1-2020.05.04                10   1  487669778            278
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_stats]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_idx_stats [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_stats l]
####################################################################################################

OUTPUT
================================

     health status index                                   uuid                   pri rep docs.count docs.deleted store.size pri.store.size
     green  open   filebeat-6.5.1-2020.05.18               HZnNju5cSGObYWgZnLvCcg  15   1  695777586            0    793.4gb        396.7gb
     green  open   filebeat-6.5.1-2020.05.19               1ozCHfdRQpWzGUnQUMe_Og  15   1  627296284            0    691.3gb        345.6gb
     green  open   filebeat-6.5.1-2020.05.17               v0-l_SAuQh2diulbwoPcuA  15   1  651301843            0    688.7gb        344.5gb
     green  open   filebeat-6.5.1-2020.05.13               sLJwkUxLRjCo6-8qdarFlQ  10   1  540150677          508    677.2gb        338.9gb
     green  open   filebeat-6.5.1-2020.05.08               dvylLEucRiOtme1bu5MsYw  10   1  592501109            0      669gb        334.1gb
     green  open   filebeat-6.5.1-2020.05.20               RScIUuACRjS-hy_8HsCjsw  15   1  589987848            0      665gb        332.4gb
     green  open   filebeat-6.5.1-2020.05.22               Ebj370D3Rz22K6ujOgbFVA  15   1  446271913            0    662.2gb        331.1gb
     green  open   filebeat-6.5.1-2020.05.21               7DcI5VnCT7WbtIwfPkMmsA  15   1  523564915           15    632.3gb          316gb
     green  open   filebeat-6.5.1-2020.05.05               cVeMW8tuTsC-V9KKHKs82Q  10   1  538873124            0    619.5gb        309.8gb
     green  open   filebeat-6.5.1-2020.04.10               ndbqpcN6QK-p1mfPKrGC2Q  10   1  551015493        12452    618.4gb        309.2gb
     green  open   filebeat-6.5.1-2020.05.06               PvFOiXUuRSaDwi41MV9LyQ  10   1  537454462            0    605.1gb        302.5gb
     green  open   filebeat-6.5.1-2020.05.15               8TOTGMkNRZeSWw1FlUnStQ  10   1  526737791            0    601.6gb        300.5gb
     green  open   filebeat-6.5.1-2020.05.14               OdSGJ0fVS2e2DuI1HPivXw  10   1  496991794            0    601.1gb        300.1gb
     green  open   filebeat-6.5.1-2020.05.16               pZuENUJQTTutXl82gC3enA  15   1  584272729            0    586.8gb        293.3gb
     green  open   filebeat-6.5.1-2020.05.12               0do2rCyhQam-9p2DOcVkoQ  10   1  470190548            0    566.2gb        283.1gb
     green  open   filebeat-6.5.1-2020.04.25               cPgS9645QfqCqTStso9rUQ  10   1  728213394            0    562.3gb          281gb
     green  open   filebeat-6.5.1-2020.04.26               oUPjXxB1SZ-TVA0ekpywnA  10   1  663323401            0    561.8gb        280.8gb
     green  open   filebeat-6.5.1-2020.04.16               I0k6QWp2TdS6C4W6qZ-9lg  10   1  490380679        16279    559.9gb        279.8gb
     green  open   filebeat-6.5.1-2020.05.04               -rmWXATBT3KdOckA7RB2Yg  10   1  487669778            0    557.6gb        278.7gb
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [delete_idx]
####################################################################################################

OUTPUT
================================

     
     USAGE: delete_idx [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_idx_cfgs]
####################################################################################################

OUTPUT
================================

     
     USAGE: showcfg_idx_cfgs [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_idx_cfgs l]
####################################################################################################

OUTPUT
================================

     
     USAGE: showcfg_idx_cfgs [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_idx_stats]
####################################################################################################

OUTPUT
================================

     
     USAGE: showcfg_idx_stats [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_idx_stats l]
####################################################################################################

OUTPUT
================================

     
     USAGE: showcfg_idx_stats [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_version_cnts]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_idx_version_cnts [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_idx_version_cnts l]
####################################################################################################

OUTPUT
================================

     occurrences  index
     -----------  -----
     1            f5-2020.05.10
     1            f5-2020.05.11
     1            f5-2020.05.12
     1            f5-2020.05.13
     1            f5-2020.05.14
     1            f5-2020.05.15
     1            f5-2020.05.16
     1            f5-2020.05.17
     1            f5-2020.05.18
     1            f5-2020.05.19
     1            f5-2020.05.20
     1            f5-2020.05.21
     1            f5-2020.05.22
     1            f5-2020.05.23
     1            filebeat-6.2.3-2020.05.20
     1            filebeat-6.2.3-2020.05.21
     1            filebeat-6.2.3-2020.05.22
     1            filebeat-6.2.3-2020.05.23
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_excluded_nodes]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_excluded_nodes [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_excluded_nodes l]
####################################################################################################

OUTPUT
================================

================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [exclude_node_name]
####################################################################################################

OUTPUT
================================

     
     USAGE: exclude_node_name [l|p|c] <node suffix--[1a|1b|1c|1d...]>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [clear_excluded_nodes]
####################################################################################################

OUTPUT
================================

     
     USAGE: clear_excluded_nodes [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [eswhoami]
####################################################################################################

OUTPUT
================================

     
     USAGE: eswhoami [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_auth_roles]
####################################################################################################

OUTPUT
================================

     
     USAGE: showcfg_auth_roles [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_auth_roles l]
####################################################################################################

OUTPUT
================================

     {
       "kibana_dashboard_only_user" : {
         "cluster" : [ ],
         "indices" : [ ],
         "applications" : [
           {
             "application" : "kibana-.kibana",
             "privileges" : [
               "read"
             ],
             "resources" : [
               "*"
             ]
           }
         ],
         "run_as" : [ ],
         "metadata" : {
           "_deprecated" : true,
           "_deprecated_reason" : "Please use Kibana feature privileges instead",
           "_reserved" : true
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_auth_rolemappings]
####################################################################################################

OUTPUT
================================

     
     USAGE: showcfg_auth_rolemappings [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [showcfg_auth_rolemappings l]
####################################################################################################

OUTPUT
================================

     {
       "bw_elasticsearch_ro" : {
         "enabled" : true,
         "roles" : [
           "bw_elasticsearch_ro"
         ],
         "rules" : {
           "all" : [
             {
               "field" : {
                 "groups" : "cn=ipausers,cn=groups,cn=accounts,dc=bandwidthclec,dc=com"
               }
             }
           ]
         },
         "metadata" : { }
       },
       "bw-es-users" : {
         "enabled" : true,
         "roles" : [
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [list_auth_roles]
####################################################################################################

OUTPUT
================================

     
     USAGE: list_auth_roles [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [list_auth_roles l]
####################################################################################################

OUTPUT
================================

     anon_monitor
     apm_system
     apm_user
     beats_admin
     beats_system
     bw_ap_tooling_metrics
     bw_elasticsearch_ro
     bw_watchers_admin
     cluster_user
     data_frame_transforms_admin
     data_frame_transforms_user
     enrich_user
     grok_debugger
     index_mbashley_read
     index_mbashley_testing
     ingest_admin
     kibana_admin
     kibana_dashboard_only_user
     kibana_system
     kibana_user
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [list_auth_rolemappings]
####################################################################################################

OUTPUT
================================

     
     USAGE: list_auth_rolemappings [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [list_auth_rolemappings l]
####################################################################################################

OUTPUT
================================

     bw-es-users
     bw_ap_tooling_metrics
     bw_elasticsearch_ro
     bw_watchers_admins
     cluster_user
     grok_debugger
     kibana
     superuser
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [evict_auth_cred_cache]
####################################################################################################

OUTPUT
================================

     
     USAGE: evict_auth_cred_cache [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [del_docs_k8s_ns_range]
####################################################################################################

OUTPUT
================================

     
     USAGE: del_docs_k8s_ns_range [l|p|c] <idx pattern> <k8s namespace> <start time> <end time>
     
     
       * TIME FORMAT: 2019-07-10T00:00:00.000Z
     
       * INDX FORMAT:
           -- filebeat-*
           -- -or- filebeat-6.5.1-2019.07.04,filebeat-6.5.1-2019.07.05,....
           -- -or- filebeat-*-2019.07*
     
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [forcemerge_to_expunge_deletes]
####################################################################################################

OUTPUT
================================

     
     USAGE: forcemerge_to_expunge_deletes [l|p|c] <idx pattern>
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [estail_deletebyquery]
####################################################################################################

OUTPUT
================================

     
     USAGE: estail_deletebyquery [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [estail_forcemerge]
####################################################################################################

OUTPUT
================================

     
     USAGE: estail_forcemerge [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [list_templates]
####################################################################################################

OUTPUT
================================

     
     USAGE: list_templates [l|p|c]
     
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [list_templates l]
####################################################################################################

OUTPUT
================================

     name                                         index_patterns                                order      version
     .data-frame-internal-1                       [.data-frame-internal-1]                      0          7020099
     .data-frame-internal-2                       [.data-frame-internal-2]                      0          7040299
     .data-frame-notifications-1                  [.data-frame-notifications-*]                 0          7040299
     .kibana_task_manager                         [.kibana_task_manager]                        0          7020099
     .logstash-management                         [.logstash]                                   0          
     .management-beats                            [.management-beats]                           0          70000
     .ml-anomalies-                               [.ml-anomalies-*]                             0          7060299
     .ml-config                                   [.ml-config]                                  0          7060299
     .ml-inference-000001                         [.ml-inference-000001]                        0          7060299
     .ml-meta                                     [.ml-meta]                                    0          7060299
     .ml-notifications                            [.ml-notifications]                           0          7040299
     .ml-notifications-000001                     [.ml-notifications-000001]                    0          7060299
     .ml-state                                    [.ml-state*]                                  0          7060299
     .monitoring-alerts                           [.monitoring-alerts-6]                        0          6070299
     .monitoring-alerts-7                         [.monitoring-alerts-7]                        0          7000199
     .monitoring-beats                            [.monitoring-beats-7-*]                       0          7000199
     .monitoring-es                               [.monitoring-es-7-*]                          0          7000199
     .monitoring-kibana                           [.monitoring-kibana-7-*]                      0          7000199
     .monitoring-logstash                         [.monitoring-logstash-7-*]                    0          7000199
================================


****************************************************************************************************
****************************************************************************************************


####################################################################################################
    CMD: [show_template]
####################################################################################################

OUTPUT
================================

     
     USAGE: show_template [l|p|c] <idx pattern>
     
     
     Examples
     ========
     show_template l filebeat-6.5.1 | grep settings -A15
     
     
================================


****************************************************************************************************
****************************************************************************************************


